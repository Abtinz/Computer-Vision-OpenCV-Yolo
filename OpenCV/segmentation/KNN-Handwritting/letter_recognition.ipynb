{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9325a37a",
   "metadata": {},
   "source": [
    "## Libraries and Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b649cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb28a873",
   "metadata": {},
   "source": [
    "Dataset: [Letter Recognition(UCI)](https://archive.ics.uci.edu/dataset/59/letter+recognition)\n",
    "\n",
    "The UCI Letter Recognition dataset is designed for training models to classify capital letters (A–Z) based on features extracted from images. It contains 20,000 samples generated from black-and-white images of letters rendered in 20 different fonts, each subjected to random distortions to simulate variability. Each sample is represented by 16 numerical attributes—such as statistical moments and edge counts—scaled to integer values between 0 and 15. These features capture aspects like the letter's position, size, pixel distribution, and edge characteristics. The dataset is commonly split into 16,000 training and 4,000 testing instances. It's particularly suitable for classification algorithms like k-Nearest Neighbors (KNN) and can be effectively utilized with OpenCV for pattern recognition tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e218067a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 17)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= np.loadtxt(\n",
    "    fname='dataset/letter-recognition.data', \n",
    "    dtype= 'float32', \n",
    "    delimiter = ',',\n",
    "    converters= {0: lambda ch: ord(ch)-ord('A')}\n",
    ")\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "47cef81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 16) (10000, 1) (10000, 16) (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing over the data\n",
    "\n",
    "# Split the dataset from the half, with 10000 samples each for training and test sets\n",
    "train, test = np.vsplit(data,2)\n",
    "\n",
    "#lets extract the train labels from the real data\n",
    "y_train = train[:,:1]\n",
    "X_train = train[:,1:]\n",
    "\n",
    "y_test = test[:,:1]\n",
    "X_test = test[:,1:]\n",
    "\n",
    "# Better and cleaner way to split the data from the half part and extract its labels from it\n",
    "y_train, X_train = np.hsplit(train,[1])\n",
    "y_test, X_test = np.hsplit(test,[1])\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "786b2e78",
   "metadata": {},
   "source": [
    "## Model - From Cv2 - KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec629a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93.06\n"
     ]
    }
   ],
   "source": [
    "knn = cv2.ml.KNearest_create()\n",
    "knn.train(X_train, cv2.ml.ROW_SAMPLE, y_train)\n",
    "\n",
    "ret, result, neighbours, dist = knn.findNearest(X_test, k=5)\n",
    "# Now we check the accuracy of classification\n",
    "matches = result==y_test\n",
    "correct = np.count_nonzero(matches)\n",
    "accuracy = correct*100.0/result.size\n",
    "print(accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
